{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependency:\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Library\n",
    "\n",
    "import json\n",
    "import wget\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from random import random\n",
    "import zipfile\n",
    "from sklearn.metrics import f1_score\n",
    "import scipy.io\n",
    "import time\n",
    "import _pickle as cp\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some thought:\n",
    "    - OPPORTUNITY Dataset Norm\n",
    "    - OPPORTUNITY slide window training data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Have fun!\n"
     ]
    }
   ],
   "source": [
    "#MASTER CONTROL PANEL\n",
    "\n",
    "#Create/ update cfg file - Select \"True\" if there is a need to update cfg Json file\n",
    "cfg_update_is_required = True\n",
    "#cfg_update_is_required = False\n",
    "\n",
    "#Download Dataset - Select \"True\" if there is a need to download Dataset into Project folder\n",
    "Dataset_download_is_required = True\n",
    "#Dataset_download_is_required = False\n",
    "\n",
    "#Select scope of the script to run\n",
    "#Select \"True\" if OPPORTUNITY DATASET related Script is required\n",
    "OPPORTUNITY_DATASET_related_Script_is_required = True\n",
    "OPPORTUNITY_DATASET_related_Script_is_required = False\n",
    "\n",
    "#Select \"True\" if SKODA DATASET related Script is required\n",
    "SKODA_DATASET_related_Script_is_required = True\n",
    "#SKODA_DATASET_related_Script_is_required = False\n",
    "\n",
    "#Auto select device(cpu/ gpu) to run\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Have fun!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, CPU will be used...\")\n",
    "\n",
    "#Select Training DATASET\n",
    "#Training_DATASET = 'OPPORTUNITY - 5 classes'\n",
    "#Training_DATASET = 'OPPORTUNITY - 18 classes'\n",
    "Training_DATASET = 'SKODA'\n",
    "\n",
    "\n",
    "#Select Data Preprocessing approach for OPPORTUNITY DATASET\n",
    "#OPPORTUNITY_DATASET_Proprocessing_approach = \"Hongxu\"\n",
    "OPPORTUNITY_DATASET_Proprocessing_approach = \"Paper\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create/ update cfg file - Run this if there is a need to update cfg Json file\n",
    "\n",
    "if cfg_update_is_required == True:\n",
    "    cfg = {}\n",
    "    cfg['OPPORTUNITY_DATASET'] = {}\n",
    "    cfg['OPPORTUNITY_DATASET']['Download_URL'] = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip'\n",
    "    cfg['OPPORTUNITY_DATASET']['Download_Destination'] = 'Dataset/OpportunityUCIDataset'\n",
    "    cfg['OPPORTUNITY_DATASET']['dataset_folder'] = 'Dataset/OpportunityUCIDataset/OpportunityUCIDataset/dataset'\n",
    "    cfg['OPPORTUNITY_DATASET']['Normalization_parameter'] = 'Dataset/OPPORTUNITY_norm_parameter.csv'\n",
    "    \n",
    "    cfg['SKODA_DATASET'] = {}\n",
    "    cfg['SKODA_DATASET']['Download_URL'] = 'http://har-dataset.org/lib/exe/fetch.php?media=wiki:dataset:skodaminicp:skodaminicp_2015_08.zip'\n",
    "    cfg['SKODA_DATASET']['Download_Destination'] = 'Dataset/SKODA_DATASET'\n",
    "    cfg['SKODA_DATASET']['dataset_path'] = 'Dataset/SKODA_DATASET/SkodaMiniCP_2015_08/right_classall_clean.mat'\n",
    "    \n",
    "    with open('cfg.json', 'w') as outfile:\n",
    "        json.dump(cfg, outfile)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "SILDE_WINDOW = 24\n",
    "SILDE_WINDOW_STEP = 12\n",
    "\n",
    "#to be automated\n",
    "SKODA_Classification_weight = [0.386610555,\n",
    "                                1.024348618,\n",
    "                                0.874884602,\n",
    "                                0.909393939,\n",
    "                                1.26013017,\n",
    "                                2.056418456,\n",
    "                                2.188381138,\n",
    "                                1.18103109,\n",
    "                                1.079755337,\n",
    "                                0.92690209,\n",
    "                                1.650109971,]\n",
    "\n",
    "\n",
    "NORM_MAX_THRESHOLDS = [3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       250,    25,     200,    5000,   5000,   5000,   5000,   5000,   5000,\n",
    "                       10000,  10000,  10000,  10000,  10000,  10000,  250,    250,    25,\n",
    "                       200,    5000,   5000,   5000,   5000,   5000,   5000,   10000,  10000,\n",
    "                       10000,  10000,  10000,  10000,  250, ]\n",
    "\n",
    "NORM_MIN_THRESHOLDS = [-3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -250,   -100,   -200,   -5000,  -5000,  -5000,  -5000,  -5000,  -5000,\n",
    "                       -10000, -10000, -10000, -10000, -10000, -10000, -250,   -250,   -100,\n",
    "                       -200,   -5000,  -5000,  -5000,  -5000,  -5000,  -5000,  -10000, -10000,\n",
    "                       -10000, -10000, -10000, -10000, -250, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load configuration parameter from Json file into a dict\n",
    "def import_cfg_file(cfg_file_path):\n",
    "    with open(cfg_file_path) as json_file:\n",
    "        cfg = json.load(json_file)\n",
    "    return cfg\n",
    "\n",
    "#Download dataset from given URL into local folder and unzip\n",
    "def download_dataset(Source_URL, Destination):\n",
    "    if not os.path.isfile(Destination + '.zip'):\n",
    "        wget.download(Source_URL, Destination + '.zip')\n",
    "    with zipfile.ZipFile(Destination + '.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(Destination)\n",
    "    #os.remove(Destination + '.zip')\n",
    "    print(' --- Dataset has been successfully downloaded into: ' + Destination)\n",
    "    return 0\n",
    "\n",
    "#Load OPPORTUNITY multi data files (DAT format), based on given file list\n",
    "#convert loaded data into pandas df, assign column names to df\n",
    "#replace NaN into 0.0\n",
    "def OPPORTUNITY_Data_Loader(OPPORTUNITY_DATASET_FILE_LIST, OPPORTUNITY_DATASET_column_names):\n",
    "    df_OPPORTUNITY_DATASET_All = ''\n",
    "    for file_name in OPPORTUNITY_DATASET_FILE_LIST:\n",
    "        if file_name.endswith(\".dat\"):\n",
    "            df_OPPORTUNITY_DATASET_current = pd.read_csv(OPPORTUNITY_DATASET_dataset_folder + '/' + file_name, sep = ' ', header = None)\n",
    "            df_OPPORTUNITY_DATASET_current.columns = OPPORTUNITY_DATASET_column_names\n",
    "            df_OPPORTUNITY_DATASET_current = df_OPPORTUNITY_DATASET_current.interpolate()\n",
    "            df_OPPORTUNITY_DATASET_current.replace(np.nan, 0.0, inplace=True)\n",
    "            df_OPPORTUNITY_DATASET_current['file_name'] = file_name\n",
    "            if type(df_OPPORTUNITY_DATASET_All) != pd.core.frame.DataFrame:\n",
    "                df_OPPORTUNITY_DATASET_All = df_OPPORTUNITY_DATASET_current\n",
    "            else:\n",
    "                df_OPPORTUNITY_DATASET_All = pd.concat([df_OPPORTUNITY_DATASET_All, df_OPPORTUNITY_DATASET_current])\n",
    "    return df_OPPORTUNITY_DATASET_All\n",
    "\n",
    "#Using raw data to generate training data based on slide window apprach\n",
    "def data_generator(ARRAY_OPPORTUNITY_DATASET_x, ARRAY_OPPORTUNITY_DATASET_y, SILDE_WINDOW, SILDE_WINDOW_STEP):\n",
    "    ARRAY_OPPORTUNITY_DATASET_x = torch.tensor(ARRAY_OPPORTUNITY_DATASET_x).float()\n",
    "    ARRAY_OPPORTUNITY_DATASET_y = torch.tensor(ARRAY_OPPORTUNITY_DATASET_y)\n",
    "    #print(type(ARRAY_OPPORTUNITY_DATASET_x))\n",
    "    array_len = len(ARRAY_OPPORTUNITY_DATASET_x)\n",
    "    shape_0 = int(array_len / SILDE_WINDOW)\n",
    "    shape_1 = SILDE_WINDOW\n",
    "    shape_2 = len(ARRAY_OPPORTUNITY_DATASET_x[0])\n",
    "    input_tensor = torch.reshape(ARRAY_OPPORTUNITY_DATASET_x[0: shape_0 * SILDE_WINDOW], (shape_0, shape_1, shape_2))\n",
    "    #print(type(input_tensor))\n",
    "    output_tensor = torch.reshape(ARRAY_OPPORTUNITY_DATASET_y[0: shape_0 * SILDE_WINDOW], (shape_0, shape_1))[:,-1]\n",
    "\n",
    "    \n",
    "\n",
    "    ARRAY_OPPORTUNITY_DATASET_x = ARRAY_OPPORTUNITY_DATASET_x[SILDE_WINDOW_STEP: ]\n",
    "    array_len = len(ARRAY_OPPORTUNITY_DATASET_x)\n",
    "    shape_0 = int(array_len / SILDE_WINDOW)\n",
    "    shape_1 = SILDE_WINDOW\n",
    "    shape_2 = len(ARRAY_OPPORTUNITY_DATASET_x[0])\n",
    "    input_tensor_part_2 = torch.reshape(ARRAY_OPPORTUNITY_DATASET_x[0: shape_0 * SILDE_WINDOW], (shape_0, shape_1, shape_2))\n",
    "    input_tensor = torch.cat((input_tensor, input_tensor_part_2), 0)\n",
    "    \n",
    "    ARRAY_OPPORTUNITY_DATASET_y = ARRAY_OPPORTUNITY_DATASET_y[SILDE_WINDOW_STEP: ]\n",
    "    output_tensor_part_2 = torch.reshape(ARRAY_OPPORTUNITY_DATASET_y[0: shape_0 * SILDE_WINDOW], (shape_0, shape_1))[:,-1]\n",
    "    output_tensor = torch.cat((output_tensor, output_tensor_part_2), 0)\n",
    "    \n",
    "    return input_tensor, output_tensor\n",
    "\n",
    "#Export Tensor into csv file\n",
    "def tensor_to_csv(tensor_name, file_name):\n",
    "    x_np = tensor_name.cpu().detach().numpy()\n",
    "    x_df = pd.DataFrame(x_np)\n",
    "    x_df.to_csv('export/' + file_name + '.csv')\n",
    "    \n",
    "    \n",
    "#Channel wise Normalization on OPPORTUNITY DATASET\n",
    "def OPPORTUNITY_Normalization(df_OPPORTUNITY_DATASET, df_OPPORTUNITY_DS_All_describe, OPPORTUNITY_col_name_selected):\n",
    "    for column_name in OPPORTUNITY_col_name_selected:\n",
    "        if column_name in ['1 MILLISEC', '244 Locomotion', '250 ML_Both_Arms', 'file_name']:\n",
    "            pass\n",
    "        else:\n",
    "            df_OPPORTUNITY_DATASET[column_name] = (df_OPPORTUNITY_DATASET[column_name] - df_OPPORTUNITY_DS_All_describe[column_name]['min']) / (df_OPPORTUNITY_DS_All_describe[column_name]['max'] - df_OPPORTUNITY_DS_All_describe[column_name]['min'])\n",
    "            df_OPPORTUNITY_DATASET[column_name].loc[df_OPPORTUNITY_DATASET[column_name] > 1] = 1\n",
    "            df_OPPORTUNITY_DATASET[column_name].loc[df_OPPORTUNITY_DATASET[column_name] < 0] = 0\n",
    "            \n",
    "    df_OPPORTUNITY_DATASET = df_OPPORTUNITY_DATASET[OPPORTUNITY_col_name_selected]\n",
    "    return df_OPPORTUNITY_DATASET\n",
    "\n",
    "\n",
    "def LOAD_OPPORTUNITY_DATASET_from_dot_DATA_file(filename):\n",
    "    f = open(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "    print(\"training data: {0}, testing data: {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df data generator - OPPORTUNITY Dataset\n",
    "#########################Pending###########################\n",
    "\n",
    "def df_data_generator(df_OPPORTUNITY_DATASET, SILDE_WINDOW, SILDE_WINDOW_STEP, OPPORTUNITY_column_name_selected):\n",
    "    file_no = 0\n",
    "    for file_name in df_OPPORTUNITY_DATASET['file_name'].unique():\n",
    "        file_no += 1\n",
    "        print(file_no)\n",
    "        df_OPPORTUNITY_DATASET_WIP = df_OPPORTUNITY_DATASET.loc[df_OPPORTUNITY_DATASET['file_name'] == file_name]\n",
    "        df_OPPORTUNITY_DATASET_WIP = df_OPPORTUNITY_DATASET_WIP[OPPORTUNITY_column_name_selected[1: ]]\n",
    "        row_no_start = 0\n",
    "        \n",
    "        \n",
    "        while (row_no_start + SILDE_WINDOW - 1) <= df_OPPORTUNITY_DATASET_WIP['2 Accelerometer RKN^ accX'].count():\n",
    "            row_no_end = row_no_start + SILDE_WINDOW\n",
    "            \n",
    "            df_input = df_OPPORTUNITY_DATASET_WIP[OPPORTUNITY_column_name_selected[1: -3]][row_no_start: row_no_end]\n",
    "            current_input = torch.tensor([df_input.values])\n",
    "            \n",
    "            df_output_Locomotion = df_OPPORTUNITY_DATASET_WIP['244 Locomotion'][row_no_end - 1]\n",
    "            \n",
    "            current_output_Locomotion = torch.tensor([df_output_Locomotion])\n",
    "            #print(current_output_Locomotion)\n",
    "            df_output_ML_Both_Arms = df_OPPORTUNITY_DATASET_WIP['250 ML_Both_Arms'][row_no_end - 1]\n",
    "            current_output_ML_Both_Arms = torch.tensor([df_output_ML_Both_Arms])\n",
    "            \n",
    "            \n",
    "            if row_no_start == 0 and file_no == 1:\n",
    "                input_tensor = current_input\n",
    "                output_Locomotion_tensor = current_output_Locomotion\n",
    "                output_ML_Both_Arms_tensor = current_output_ML_Both_Arms\n",
    "            else:\n",
    "                input_tensor = torch.cat((input_tensor, current_input), 0)\n",
    "                output_Locomotion_tensor = torch.cat((output_Locomotion_tensor, current_output_Locomotion), 0)\n",
    "                output_ML_Both_Arms_tensor = torch.cat((output_ML_Both_Arms_tensor, current_output_ML_Both_Arms), 0)\n",
    "                \n",
    "            row_no_start += SILDE_WINDOW_STEP\n",
    "            #print(input_tensor.size())\n",
    "            #print(input_tensor)\n",
    "    return input_tensor, output_Locomotion_tensor, output_ML_Both_Arms_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cfg file:\n",
    "\n",
    "cfg_file_path = 'cfg.json'\n",
    "cfg = import_cfg_file(cfg_file_path)\n",
    "\n",
    "#OPPORTUNITY Dataset related configuration\n",
    "URL_OPPORTUNITY_DATASET = cfg['OPPORTUNITY_DATASET']['Download_URL']\n",
    "Download_Destination_OPPORTUNITY_DATASET = cfg['OPPORTUNITY_DATASET']['Download_Destination']\n",
    "OPPORTUNITY_DATASET_dataset_folder = cfg['OPPORTUNITY_DATASET']['dataset_folder']\n",
    "OPPORTUNITY_DATASET_Normalization_parameter = cfg['OPPORTUNITY_DATASET']['Normalization_parameter']\n",
    "\n",
    "#SKODA Dataset related configuration\n",
    "URL_SKODA_DATASET = cfg['SKODA_DATASET']['Download_URL']\n",
    "Download_Destination_SKODA_DATASET = cfg['SKODA_DATASET']['Download_Destination']\n",
    "SKODA_DATASET_dataset_path = cfg['SKODA_DATASET']['dataset_path']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 84028489 / 84028489 --- Dataset has been successfully downloaded into: Dataset/SKODA_DATASET\n"
     ]
    }
   ],
   "source": [
    "#Run this if there is a need to download Dataset into Project folder\n",
    "\n",
    "if Dataset_download_is_required == True:\n",
    "    if OPPORTUNITY_DATASET_related_Script_is_required == True:\n",
    "        download_dataset(URL_OPPORTUNITY_DATASET, Download_Destination_OPPORTUNITY_DATASET)\n",
    "    if SKODA_DATASET_related_Script_is_required == True:\n",
    "        download_dataset(URL_SKODA_DATASET, Download_Destination_SKODA_DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Opportunity Dataset column names\n",
    "\n",
    "\n",
    "if OPPORTUNITY_DATASET_Proprocessing_approach == \"Hongxu\":\n",
    "    if OPPORTUNITY_DATASET_related_Script_is_required == True:\n",
    "        with open(OPPORTUNITY_DATASET_dataset_folder + '/column_names.txt') as txt_file:\n",
    "            OPPORTUNITY_DATASET_column_name = txt_file.read().splitlines()\n",
    "\n",
    "        column_names = []\n",
    "        for column_name in OPPORTUNITY_DATASET_column_name:\n",
    "            column_name = re.split('; |: ', column_name)\n",
    "            if column_name[0] == 'Column':\n",
    "                column_names.append(column_name[1])\n",
    "            #print(column_name)\n",
    "        OPPORTUNITY_DATASET_column_names = column_names\n",
    "\n",
    "        #filter out column names selected for training\n",
    "\n",
    "        OPPORTUNITY_column_inclusive = ['InertialMeasurementUnit', 'Locomotion', 'ML_Both_Arms']\n",
    "        OPPORTUNITY_column_exclusive = ['Quaternion']\n",
    "\n",
    "        OPPORTUNITY_column_name_selected = OPPORTUNITY_DATASET_column_names[0: 37]\n",
    "        for column_name in OPPORTUNITY_DATASET_column_names:\n",
    "            inclusive_index = 0\n",
    "            exclusive_index = 1\n",
    "            for keyword_inclusive in OPPORTUNITY_column_inclusive:\n",
    "                if column_name.find(keyword_inclusive) != -1:\n",
    "                    inclusive_index = 1\n",
    "                    break\n",
    "            for keyword_exclusive in OPPORTUNITY_column_exclusive:\n",
    "                if column_name.find(keyword_exclusive) != -1:\n",
    "                    exclusive_index = 0\n",
    "                    break\n",
    "            if inclusive_index * exclusive_index == 1:\n",
    "                OPPORTUNITY_column_name_selected.append(column_name)\n",
    "\n",
    "        OPPORTUNITY_column_name_selected.append('file_name')\n",
    "\n",
    "        OPPORTUNITY_column_name_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Opportunity Dataset dat file into 3 Groups based on paper: Training, Validation, Testing\n",
    "\n",
    "if OPPORTUNITY_DATASET_Proprocessing_approach == \"Hongxu\":\n",
    "    if OPPORTUNITY_DATASET_related_Script_is_required == True:\n",
    "        OPPORTUNITY_DATASET_FILE_LIST = os.listdir(OPPORTUNITY_DATASET_dataset_folder)\n",
    "        OPPORTUNITY_DATASET_FILE_LIST\n",
    "\n",
    "        OPPORTUNITY_DATASET_FILE_LIST_Training = []\n",
    "        OPPORTUNITY_DATASET_FILE_LIST_Validation = []\n",
    "        OPPORTUNITY_DATASET_FILE_LIST_Testing = []\n",
    "\n",
    "        for file_name in OPPORTUNITY_DATASET_FILE_LIST:\n",
    "            if file_name.endswith(\".dat\"):\n",
    "                if 'S4' in file_name:\n",
    "                    continue\n",
    "                if 'S1' in file_name:\n",
    "                    OPPORTUNITY_DATASET_FILE_LIST_Training.append(file_name)\n",
    "                elif 'ADL3' in file_name:\n",
    "                    OPPORTUNITY_DATASET_FILE_LIST_Validation.append(file_name)\n",
    "                elif ('ADL4' in file_name) or ('ADL5' in file_name):\n",
    "                    OPPORTUNITY_DATASET_FILE_LIST_Testing.append(file_name)\n",
    "                else:\n",
    "                    OPPORTUNITY_DATASET_FILE_LIST_Training.append(file_name)\n",
    "\n",
    "        OPPORTUNITY_DATASET_FILE_LIST_Training\n",
    "        OPPORTUNITY_DATASET_FILE_LIST_Validation\n",
    "        OPPORTUNITY_DATASET_FILE_LIST_Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPPORTUNITY_DATASET Normalization\n",
    "Using_Paper_OPPORTUNITY_Threshold = True\n",
    "#Using_Paper_OPPORTUNITY_Threshold = False\n",
    "\n",
    "if OPPORTUNITY_DATASET_Proprocessing_approach == \"Hongxu\":\n",
    "    if OPPORTUNITY_DATASET_related_Script_is_required == True:\n",
    "\n",
    "        #load OPPORTUNITY_DATASET_Normalization_parameter\n",
    "        if os.path.isfile(OPPORTUNITY_DATASET_Normalization_parameter):\n",
    "            df_OPPORTUNITY_DATASET_All_describe = pd.read_csv(OPPORTUNITY_DATASET_Normalization_parameter, index_col = 0)\n",
    "        else:\n",
    "            df_OPPORTUNITY_DATASET_All = OPPORTUNITY_Data_Loader(OPPORTUNITY_DATASET_FILE_LIST, OPPORTUNITY_DATASET_column_names)\n",
    "\n",
    "            #df_OPPORTUNITY_DATASET_All.describe()\n",
    "            df_OPPORTUNITY_DATASET_All_describe = df_OPPORTUNITY_DATASET_All.describe()\n",
    "            #release memory\n",
    "            df_OPPORTUNITY_DATASET_All = ''\n",
    "            df_OPPORTUNITY_DATASET_All_describe.to_csv(OPPORTUNITY_DATASET_Normalization_parameter)\n",
    "\n",
    "        if Using_Paper_OPPORTUNITY_Threshold == True:\n",
    "            df_OPPORTUNITY_DATASET_All_describe.loc[['min'], [col_name for col_name in OPPORTUNITY_column_name_selected[1: -3]]] = NORM_MIN_THRESHOLDS\n",
    "            df_OPPORTUNITY_DATASET_All_describe.loc[['max'], [col_name for col_name in OPPORTUNITY_column_name_selected[1: -3]]] = NORM_MAX_THRESHOLDS\n",
    "\n",
    "\n",
    "        df_OPPORTUNITY_DATASET_Training = OPPORTUNITY_Data_Loader(OPPORTUNITY_DATASET_FILE_LIST_Training, OPPORTUNITY_DATASET_column_names)\n",
    "        df_OPPORTUNITY_DATASET_Validation = OPPORTUNITY_Data_Loader(OPPORTUNITY_DATASET_FILE_LIST_Validation, OPPORTUNITY_DATASET_column_names)\n",
    "        df_OPPORTUNITY_DATASET_Testing = OPPORTUNITY_Data_Loader(OPPORTUNITY_DATASET_FILE_LIST_Testing, OPPORTUNITY_DATASET_column_names)\n",
    "\n",
    "        df_OPPORTUNITY_DATASET_Training_WIP = OPPORTUNITY_Normalization(df_OPPORTUNITY_DATASET_Training, df_OPPORTUNITY_DATASET_All_describe, OPPORTUNITY_column_name_selected)\n",
    "        df_OPPORTUNITY_DATASET_Validation_WIP = OPPORTUNITY_Normalization(df_OPPORTUNITY_DATASET_Validation, df_OPPORTUNITY_DATASET_All_describe, OPPORTUNITY_column_name_selected)\n",
    "        df_OPPORTUNITY_DATASET_Testing_WIP = OPPORTUNITY_Normalization(df_OPPORTUNITY_DATASET_Testing, df_OPPORTUNITY_DATASET_All_describe, OPPORTUNITY_column_name_selected)\n",
    "\n",
    "        Classifications = df_OPPORTUNITY_DATASET_Training_WIP['250 ML_Both_Arms'].unique()\n",
    "        dict_18_classification = {}\n",
    "        class_index = 0\n",
    "        for Classitication in Classifications:\n",
    "            dict_18_classification[Classitication] = class_index\n",
    "            class_index += 1\n",
    "\n",
    "        df_OPPORTUNITY_DATASET_Training_WIP['250 ML_Both_Arms'] = df_OPPORTUNITY_DATASET_Training_WIP['250 ML_Both_Arms'].apply(lambda  x: dict_18_classification[x])\n",
    "        df_OPPORTUNITY_DATASET_Testing_WIP['250 ML_Both_Arms'] = df_OPPORTUNITY_DATASET_Testing_WIP['250 ML_Both_Arms'].apply(lambda  x: dict_18_classification[x])\n",
    "        df_OPPORTUNITY_DATASET_Validation_WIP['250 ML_Both_Arms'] = df_OPPORTUNITY_DATASET_Validation_WIP['250 ML_Both_Arms'].apply(lambda  x: dict_18_classification[x])\n",
    "\n",
    "        \"\"\"\n",
    "        Training_x, Training_y_1, Training_y_2 = df_data_generator(df_OPPORTUNITY_DATASET_Training_WIP, SILDE_WINDOW, SILDE_WINDOW_STEP, OPPORTUNITY_column_name_selected)\n",
    "        Training_x = torch.reshape(Training_x, (Training_x.size()[0], 1, Training_x.size()[1], Training_x.size()[2])).float()\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        Testing_x, Testing_y_1, Testing_y_2 = df_data_generator(df_OPPORTUNITY_DATASET_Testing_WIP, SILDE_WINDOW, SILDE_WINDOW_STEP, OPPORTUNITY_column_name_selected)\n",
    "        Testing_x = torch.reshape(Testing_x, (Testing_x.size()[0], 1, Testing_x.size()[1], Testing_x.size()[2])).float()\n",
    "\n",
    "        Validation_x, Validation_y_1, Validation_y_2 = df_data_generator(df_OPPORTUNITY_DATASET_Validation_WIP, SILDE_WINDOW, SILDE_WINDOW_STEP, OPPORTUNITY_column_name_selected)\n",
    "        Validation_x = torch.reshape(Validation_x, (Validation_x.size()[0], 1, Validation_x.size()[1], Validation_x.size()[2])).float()\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert OPPORTUNITY Dateset into .data file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing - OPPORTUNITY Dataset - Paper approach\n",
    "\n",
    "if OPPORTUNITY_DATASET_Proprocessing_approach == \"Paper\":\n",
    "    if OPPORTUNITY_DATASET_related_Script_is_required == True:\n",
    "        OPPORTUNITY_dot_DATA_file_path = 'Dataset/oppChallenge_gestures.data'\n",
    "        if not os.path.isfile(OPPORTUNITY_dot_DATA_file_path):\n",
    "            print('Data pre processing in progress...')\n",
    "            !python preprocess_data.py -i Dataset/OpportunityUCIDataset.zip -o oppChallenge_gestures.data\n",
    "            print('Data pre processing completed!')\n",
    "\n",
    "        OPPORTUNITY_X_train, OPPORTUNITY_y_train, OPPORTUNITY_X_test, OPPORTUNITY_y_test = LOAD_OPPORTUNITY_DATASET_from_dot_DATA_file(OPPORTUNITY_dot_DATA_file_path)\n",
    "\n",
    "        df_OPPORTUNITY_y_target = pd.DataFrame(OPPORTUNITY_y_train)\n",
    "        df_OPPORTUNITY_y_target.columns = ['classification']\n",
    "        OPPORTUNITY_class_count = df_OPPORTUNITY_y_target['classification'].value_counts()\n",
    "        OPPORTUNITY_class_count = OPPORTUNITY_class_count.sort_index(0).tolist()\n",
    "        OPPORTUNITY_class_weight = 1 / (np.array(OPPORTUNITY_class_count) / (sum(OPPORTUNITY_class_count) / len(OPPORTUNITY_class_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKODA DATASET - preprocessing\n",
    "\n",
    "if SKODA_DATASET_related_Script_is_required == True:\n",
    "    right_classall_clean_mat = scipy.io.loadmat(SKODA_DATASET_dataset_path)\n",
    "    right_classall_clean_array = right_classall_clean_mat['right_classall_clean']\n",
    "\n",
    "    SKODA_DATASET_dataset_size = right_classall_clean_array.shape[0]\n",
    "    SKODA_Selected_row = [int(k * (98 / 30)) for k in range(0, int(SKODA_DATASET_dataset_size / (98 / 30)) + 1)]\n",
    "    #print(SKODA_Selected_row)\n",
    "\n",
    "    no_of_sensor = 10\n",
    "    SKODA_Selected_column_x = [2 + s * 7 for s in range(no_of_sensor)] + [3 + s * 7 for s in range(no_of_sensor)] + [4 + s * 7 for s in range(no_of_sensor)]\n",
    "    SKODA_Selected_column_x.sort()\n",
    "    SKODA_Selected_column_y = 0\n",
    "\n",
    "    right_classall_clean_array = right_classall_clean_array[SKODA_Selected_row,:].astype(np.float)\n",
    "    right_classall_clean_array_x = right_classall_clean_array[:, SKODA_Selected_column_x]\n",
    "    right_classall_clean_array_y = right_classall_clean_array[:, SKODA_Selected_column_y]\n",
    "\n",
    "    #print(right_classall_clean_array_x.shape)\n",
    "    #print(SKODA_Selected_column_x)\n",
    "    right_classall_clean_array\n",
    "    SKODA_Selected_column_norm = []\n",
    "    for column in range(len(right_classall_clean_array_x[0])):\n",
    "        max_value = max(right_classall_clean_array_x[:, column])\n",
    "        min_value = min(right_classall_clean_array_x[:, column])\n",
    "        SKODA_Selected_column_norm.append([max_value, min_value, (max_value - min_value)])\n",
    "        #Norm\n",
    "        #right_classall_clean_array_x[:, column] = (right_classall_clean_array_x[:, column] - min_value) / (max_value - min_value)\n",
    "\n",
    "    #len(SKODA_Selected_column_norm)\n",
    "    #right_classall_clean_array_x.shape\n",
    "\n",
    "    SKODA_original_class = np.unique(right_classall_clean_array_y)\n",
    "    dict_SKODA_class = {}\n",
    "    for i in range(len(SKODA_original_class)):\n",
    "        dict_SKODA_class[SKODA_original_class[i]] = i\n",
    "    for i in range(len(right_classall_clean_array_y)):\n",
    "        right_classall_clean_array_y[i] = dict_SKODA_class[right_classall_clean_array_y[i]]\n",
    "\n",
    "    SKODA_X_train_tensor, SKODA_y_train_tensor = data_generator(right_classall_clean_array_x, right_classall_clean_array_y, SILDE_WINDOW, SILDE_WINDOW_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN_LSTM_HAR_MODEL(nn.Module):\n",
    "    def __init__(self, SILDE_WINDOW, no_of_class, no_of_sensor_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.no_of_class = no_of_class\n",
    "        \n",
    "        self.conv_channel = 64\n",
    "        self.kernel_size = (5, 1)\n",
    "        self.hidden_dim = 128\n",
    "        self.no_of_conv_layer = 4\n",
    "        self.lstm_dropout = 0.5\n",
    "        self.final_sequence_length = SILDE_WINDOW - self.no_of_conv_layer * (self.kernel_size[0] - 1)\n",
    "        self.lstm1_input_size = self.conv_channel * no_of_sensor_channel\n",
    "        \n",
    "        self.input_bn = nn.BatchNorm2d(no_of_sensor_channel, affine = False)\n",
    "        \n",
    "        self.cnn2d_1 = nn.Conv2d(in_channels = 1, out_channels = self.conv_channel, kernel_size = self.kernel_size)\n",
    "        self.conv1_bn = nn.BatchNorm2d(self.conv_channel)\n",
    "        \n",
    "        self.cnn2d_2 = nn.Conv2d(in_channels = self.conv_channel, out_channels = self.conv_channel, kernel_size = self.kernel_size)\n",
    "        self.conv2_bn = nn.BatchNorm2d(self.conv_channel)\n",
    "        \n",
    "        self.cnn2d_3 = nn.Conv2d(in_channels = self.conv_channel, out_channels = self.conv_channel, kernel_size = self.kernel_size)\n",
    "        self.conv3_bn = nn.BatchNorm2d(self.conv_channel)\n",
    "        \n",
    "        self.cnn2d_4 = nn.Conv2d(in_channels = self.conv_channel, out_channels = self.conv_channel, kernel_size = self.kernel_size)\n",
    "        self.conv4_bn = nn.BatchNorm2d(self.conv_channel)\n",
    "        \n",
    "        #self.conv_bn = nn.BatchNorm1d(self.final_sequence_length)\n",
    "        self.conv_bn = nn.BatchNorm2d(no_of_sensor_channel, affine = False)\n",
    "        #self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(batch_first = True, num_layers = 2, input_size  = self.lstm1_input_size, hidden_size = self.hidden_dim)\n",
    "        self.lstm_bn = nn.BatchNorm1d(self.final_sequence_length, affine = False)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.lstm1 = nn.LSTM(batch_first = True, input_size  = self.lstm1_input_size, hidden_size = self.hidden_dim)\n",
    "        self.lstm1_bn = nn.BatchNorm1d(self.final_sequence_length)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(batch_first = True, input_size  = self.hidden_dim, hidden_size = self.hidden_dim)\n",
    "        self.lstm2_bn = nn.BatchNorm1d(self.final_sequence_length)\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Linear(128, self.no_of_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        \n",
    "        x = torch.transpose(x, 1, 3)\n",
    "        x = self.input_bn(x)\n",
    "        x = torch.transpose(x, 1, 3)\n",
    "        \n",
    "        x = self.cnn2d_1(x)\n",
    "        x = F.relu(x)\n",
    "        #x = self.conv1_bn(x)\n",
    "        #tensor_to_csv(x[0, -1, :, :], 'layer_1_data_0')\n",
    "        #tensor_to_csv(x[5, -1, :, :], 'layer_1_data_100')\n",
    "        \n",
    "        x = self.cnn2d_2(x)\n",
    "        x = F.relu(x)\n",
    "        #x = self.conv2_bn(x)\n",
    "        #tensor_to_csv(x[0, -1, :, :], 'layer_2_data_0')\n",
    "        #tensor_to_csv(x[5, -1, :, :], 'layer_2_data_100')\n",
    "\n",
    "        x = self.cnn2d_3(x)\n",
    "        x = F.relu(x)\n",
    "        #x = self.conv3_bn(x)\n",
    "        #tensor_to_csv(x[0, -1, :, :], 'layer_3_data_0')\n",
    "        #tensor_to_csv(x[5, -1, :, :], 'layer_3_data_100')\n",
    "\n",
    "        x = self.cnn2d_4(x)\n",
    "        x = F.relu(x)\n",
    "        #x = self.conv4_bn(x)\n",
    "        #tensor_to_csv(x[0, -1, :, :], 'layer_4_data_0')\n",
    "        #tensor_to_csv(x[5, -1, :, :], 'layer_4_data_100')\n",
    "        \n",
    "        x = torch.transpose(x, 1, 3)\n",
    "        x = self.conv_bn(x)\n",
    "        x = torch.transpose(x, 1, 3)\n",
    "        \n",
    "        #print(x.size())\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        #print(x.size())\n",
    "        x = torch.reshape(x, (x.size()[0], x.size()[1], -1))\n",
    "        \n",
    "        #hidden = self.init_hidden()\n",
    "        #hidden = (torch.randn(2, x.size()[0], self.hidden_dim).cuda(), torch.randn(2, x.size()[0], self.hidden_dim).cuda())\n",
    "        #x, hidden = self.lstm1(x, hidden)\n",
    "        \n",
    "        x, hidden = self.lstm(x)\n",
    "        x = self.lstm_bn(x)\n",
    "        \n",
    "        \"\"\"\n",
    "        x, hidden = self.lstm1(x)\n",
    "        x = self.lstm1_bn(x)\n",
    "        #hidden = self.lstm1_bn(hidden)\n",
    "        x, hidden = self.lstm2(x)\n",
    "        x = self.lstm2_bn(x)\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        #print(x)\n",
    "        #x = self.conv_bn2(x)\n",
    "        #hidden = self.conv_bn2(hidden)\n",
    "        #tensor_to_csv(x[0, -1, :,], 'layer_lstm1_data_0')\n",
    "        #tensor_to_csv(x[5, -1, :], 'layer_lstm1_data_100')\n",
    "        #print(x)\n",
    "        #hidden2 = (torch.zeros(self.n_layers, 8, self.hidden_dim).requires_grad_(), torch.zeros(self.n_layers, 8, self.hidden_dim).requires_grad_())\n",
    "        ###############################\n",
    "        #x, hidden = self.lstm2(x, hidden)\n",
    "        #print(x)\n",
    "        #x = self.conv_bn2(x)\n",
    "        #tensor_to_csv(x[0, -1, :,], 'layer_lstm2_data_0')\n",
    "        #tensor_to_csv(x[15, -1, :], 'layer_lstm2_data_100')\n",
    "        \n",
    "        #print(x.size())\n",
    "        x = torch.reshape(x, (-1, self.hidden_dim))\n",
    "        #print(x.size())\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        #x = F.softmax(x)\n",
    "        #int(x.size()[0] / self.final_sequence_length)\n",
    "        x = torch.reshape(x, (-1, self.final_sequence_length, self.no_of_class))\n",
    "        #x = x[:, -1, :]\n",
    "        #print(x.size())\n",
    "        #tensor_to_csv(x, 'layer_fc1_data')\n",
    "        #tensor_to_csv(x, 'output_data')\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240, Loss: 434.119141, F_score: 0.035390, Accuracy: 0.098412\n",
      "Epoch 2/240, Loss: 430.566650, F_score: 0.043841, Accuracy: 0.124514\n",
      "Epoch 3/240, Loss: 431.980255, F_score: 0.098993, Accuracy: 0.239531\n",
      "Epoch 4/240, Loss: 434.597595, F_score: 0.019562, Accuracy: 0.103910\n",
      "Epoch 5/240, Loss: 433.600433, F_score: 0.017521, Accuracy: 0.098078\n",
      "Epoch 6/240, Loss: 430.494659, F_score: 0.058689, Accuracy: 0.118572\n",
      "Epoch 7/240, Loss: 425.269775, F_score: 0.149179, Accuracy: 0.260857\n",
      "Epoch 8/240, Loss: 423.628876, F_score: 0.167783, Accuracy: 0.281129\n",
      "Epoch 9/240, Loss: 427.572174, F_score: 0.146662, Accuracy: 0.208153\n",
      "Epoch 10/240, Loss: 426.852753, F_score: 0.149610, Accuracy: 0.276908\n",
      "Epoch 11/240, Loss: 421.625458, F_score: 0.179368, Accuracy: 0.288348\n",
      "Epoch 12/240, Loss: 422.160370, F_score: 0.187237, Accuracy: 0.213373\n",
      "Epoch 13/240, Loss: 414.155548, F_score: 0.315762, Accuracy: 0.364656\n",
      "Epoch 14/240, Loss: 421.281921, F_score: 0.109202, Accuracy: 0.161724\n",
      "Epoch 15/240, Loss: 416.774231, F_score: 0.149198, Accuracy: 0.206542\n",
      "Epoch 16/240, Loss: 414.840546, F_score: 0.238852, Accuracy: 0.317339\n",
      "Epoch 17/240, Loss: 414.856995, F_score: 0.246460, Accuracy: 0.325003\n",
      "Epoch 18/240, Loss: 419.357727, F_score: 0.205893, Accuracy: 0.222648\n",
      "Epoch 19/240, Loss: 408.897949, F_score: 0.295209, Accuracy: 0.368433\n",
      "Epoch 20/240, Loss: 410.656647, F_score: 0.238365, Accuracy: 0.259080\n",
      "Epoch 21/240, Loss: 407.574371, F_score: 0.318349, Accuracy: 0.368877\n",
      "Epoch 22/240, Loss: 403.798370, F_score: 0.285773, Accuracy: 0.316395\n",
      "Epoch 23/240, Loss: 400.093414, F_score: 0.356908, Accuracy: 0.414640\n",
      "Epoch 24/240, Loss: 402.311035, F_score: 0.316571, Accuracy: 0.342997\n",
      "Epoch 25/240, Loss: 401.794556, F_score: 0.337179, Accuracy: 0.394424\n",
      "Epoch 26/240, Loss: 395.638794, F_score: 0.341446, Accuracy: 0.349272\n",
      "Epoch 27/240, Loss: 397.189758, F_score: 0.365395, Accuracy: 0.417861\n",
      "Epoch 28/240, Loss: 394.292175, F_score: 0.376745, Accuracy: 0.419360\n",
      "Epoch 29/240, Loss: 402.852295, F_score: 0.295766, Accuracy: 0.322448\n",
      "Epoch 30/240, Loss: 400.422699, F_score: 0.349694, Accuracy: 0.377041\n",
      "Epoch 31/240, Loss: 396.290497, F_score: 0.403117, Accuracy: 0.447851\n",
      "Epoch 32/240, Loss: 390.895996, F_score: 0.337177, Accuracy: 0.363101\n",
      "Epoch 33/240, Loss: 388.103394, F_score: 0.462216, Accuracy: 0.485949\n",
      "Epoch 34/240, Loss: 386.709778, F_score: 0.442506, Accuracy: 0.445740\n",
      "Epoch 35/240, Loss: 389.198914, F_score: 0.438159, Accuracy: 0.475397\n",
      "Epoch 36/240, Loss: 377.765747, F_score: 0.479935, Accuracy: 0.502333\n",
      "Epoch 37/240, Loss: 378.601532, F_score: 0.529292, Accuracy: 0.539043\n",
      "Epoch 38/240, Loss: 378.021179, F_score: 0.474184, Accuracy: 0.499833\n",
      "Epoch 39/240, Loss: 380.246246, F_score: 0.508169, Accuracy: 0.524547\n",
      "Epoch 40/240, Loss: 377.647522, F_score: 0.488362, Accuracy: 0.505720\n",
      "Epoch 41/240, Loss: 368.160156, F_score: 0.528807, Accuracy: 0.532656\n",
      "Epoch 42/240, Loss: 368.249054, F_score: 0.574046, Accuracy: 0.585694\n",
      "Epoch 43/240, Loss: 370.922638, F_score: 0.553615, Accuracy: 0.561257\n",
      "Epoch 44/240, Loss: 375.990417, F_score: 0.479494, Accuracy: 0.497667\n",
      "Epoch 45/240, Loss: 369.637970, F_score: 0.528871, Accuracy: 0.535988\n",
      "Epoch 46/240, Loss: 374.011993, F_score: 0.525309, Accuracy: 0.537710\n",
      "Epoch 47/240, Loss: 370.656342, F_score: 0.534819, Accuracy: 0.548928\n",
      "Epoch 48/240, Loss: 366.929230, F_score: 0.483400, Accuracy: 0.501055\n",
      "Epoch 49/240, Loss: 365.346710, F_score: 0.586036, Accuracy: 0.603188\n",
      "Epoch 50/240, Loss: 363.616486, F_score: 0.474263, Accuracy: 0.494113\n",
      "Epoch 51/240, Loss: 358.195740, F_score: 0.585459, Accuracy: 0.604576\n",
      "Epoch 52/240, Loss: 357.151031, F_score: 0.594433, Accuracy: 0.595024\n",
      "Epoch 53/240, Loss: 360.375885, F_score: 0.590753, Accuracy: 0.615017\n",
      "Epoch 54/240, Loss: 363.921509, F_score: 0.499214, Accuracy: 0.498500\n",
      "Epoch 55/240, Loss: 359.486694, F_score: 0.595975, Accuracy: 0.601077\n",
      "Epoch 56/240, Loss: 349.521942, F_score: 0.649349, Accuracy: 0.648451\n",
      "Epoch 57/240, Loss: 347.505402, F_score: 0.633144, Accuracy: 0.644618\n",
      "Epoch 58/240, Loss: 351.666168, F_score: 0.639330, Accuracy: 0.634233\n",
      "Epoch 59/240, Loss: 355.991028, F_score: 0.602750, Accuracy: 0.612685\n",
      "Epoch 60/240, Loss: 346.476227, F_score: 0.648875, Accuracy: 0.656503\n",
      "Epoch 61/240, Loss: 340.785461, F_score: 0.672698, Accuracy: 0.678607\n",
      "Epoch 62/240, Loss: 345.667816, F_score: 0.661270, Accuracy: 0.665945\n",
      "Epoch 63/240, Loss: 352.784058, F_score: 0.598887, Accuracy: 0.610741\n",
      "Epoch 64/240, Loss: 350.389648, F_score: 0.654916, Accuracy: 0.656226\n",
      "Epoch 65/240, Loss: 342.375061, F_score: 0.580201, Accuracy: 0.604021\n",
      "Epoch 66/240, Loss: 343.104950, F_score: 0.680981, Accuracy: 0.678829\n",
      "Epoch 67/240, Loss: 342.108673, F_score: 0.657842, Accuracy: 0.670554\n",
      "Epoch 68/240, Loss: 340.603119, F_score: 0.692005, Accuracy: 0.695657\n",
      "Epoch 69/240, Loss: 340.241180, F_score: 0.639135, Accuracy: 0.651783\n",
      "Epoch 70/240, Loss: 340.990479, F_score: 0.656469, Accuracy: 0.653727\n",
      "Epoch 71/240, Loss: 337.694641, F_score: 0.700345, Accuracy: 0.704376\n",
      "Epoch 72/240, Loss: 335.935028, F_score: 0.701713, Accuracy: 0.697490\n",
      "Epoch 73/240, Loss: 336.193146, F_score: 0.709182, Accuracy: 0.713262\n",
      "Epoch 74/240, Loss: 338.154053, F_score: 0.697605, Accuracy: 0.695601\n",
      "Epoch 75/240, Loss: 353.103577, F_score: 0.599088, Accuracy: 0.608686\n",
      "Epoch 76/240, Loss: 346.883514, F_score: 0.644360, Accuracy: 0.658614\n",
      "Epoch 77/240, Loss: 350.693787, F_score: 0.577814, Accuracy: 0.589248\n",
      "Epoch 78/240, Loss: 347.697845, F_score: 0.648300, Accuracy: 0.664834\n",
      "Epoch 79/240, Loss: 336.819641, F_score: 0.659267, Accuracy: 0.663890\n",
      "Epoch 80/240, Loss: 340.102173, F_score: 0.705164, Accuracy: 0.706209\n",
      "Epoch 81/240, Loss: 332.470154, F_score: 0.708608, Accuracy: 0.714928\n",
      "Epoch 82/240, Loss: 334.704498, F_score: 0.698603, Accuracy: 0.698545\n",
      "Epoch 83/240, Loss: 335.705902, F_score: 0.677534, Accuracy: 0.692103\n",
      "Epoch 84/240, Loss: 333.621674, F_score: 0.686531, Accuracy: 0.686105\n",
      "Epoch 85/240, Loss: 335.783844, F_score: 0.683036, Accuracy: 0.688271\n",
      "Epoch 86/240, Loss: 334.080719, F_score: 0.697733, Accuracy: 0.695435\n",
      "Epoch 87/240, Loss: 332.481873, F_score: 0.735564, Accuracy: 0.738032\n",
      "Epoch 88/240, Loss: 329.402374, F_score: 0.651972, Accuracy: 0.674442\n",
      "Epoch 89/240, Loss: 334.262878, F_score: 0.723549, Accuracy: 0.723426\n",
      "Epoch 90/240, Loss: 324.123047, F_score: 0.732123, Accuracy: 0.737032\n",
      "Epoch 91/240, Loss: 322.293304, F_score: 0.764471, Accuracy: 0.767522\n",
      "Epoch 92/240, Loss: 325.320648, F_score: 0.714838, Accuracy: 0.725925\n",
      "Epoch 93/240, Loss: 329.355896, F_score: 0.731789, Accuracy: 0.739309\n",
      "Epoch 94/240, Loss: 324.166107, F_score: 0.752390, Accuracy: 0.758414\n",
      "Epoch 95/240, Loss: 328.861328, F_score: 0.696433, Accuracy: 0.709208\n",
      "Epoch 96/240, Loss: 340.672546, F_score: 0.678931, Accuracy: 0.679662\n",
      "Epoch 97/240, Loss: 336.590240, F_score: 0.686485, Accuracy: 0.689492\n",
      "Epoch 98/240, Loss: 332.525909, F_score: 0.723692, Accuracy: 0.723426\n",
      "Epoch 99/240, Loss: 329.013153, F_score: 0.668730, Accuracy: 0.685605\n",
      "Epoch 100/240, Loss: 332.208710, F_score: 0.729743, Accuracy: 0.729812\n",
      "Epoch 101/240, Loss: 326.675812, F_score: 0.711125, Accuracy: 0.723203\n",
      "Epoch 102/240, Loss: 324.027802, F_score: 0.757178, Accuracy: 0.755248\n",
      "Epoch 103/240, Loss: 326.724243, F_score: 0.666118, Accuracy: 0.691992\n",
      "Epoch 104/240, Loss: 328.745270, F_score: 0.747983, Accuracy: 0.744030\n",
      "Epoch 105/240, Loss: 321.908569, F_score: 0.733891, Accuracy: 0.743141\n",
      "Epoch 106/240, Loss: 325.022766, F_score: 0.756240, Accuracy: 0.759636\n",
      "Epoch 107/240, Loss: 322.436188, F_score: 0.709121, Accuracy: 0.723370\n",
      "Epoch 108/240, Loss: 319.540527, F_score: 0.773619, Accuracy: 0.777463\n",
      "Epoch 109/240, Loss: 323.247864, F_score: 0.693807, Accuracy: 0.712596\n",
      "Epoch 110/240, Loss: 322.328644, F_score: 0.761780, Accuracy: 0.765189\n",
      "Epoch 111/240, Loss: 320.408203, F_score: 0.734103, Accuracy: 0.744307\n",
      "Epoch 112/240, Loss: 322.096405, F_score: 0.750543, Accuracy: 0.757025\n",
      "Epoch 113/240, Loss: 322.788757, F_score: 0.725308, Accuracy: 0.735255\n",
      "Epoch 114/240, Loss: 320.098267, F_score: 0.765802, Accuracy: 0.767411\n",
      "Epoch 115/240, Loss: 315.551880, F_score: 0.764831, Accuracy: 0.776574\n",
      "Epoch 116/240, Loss: 315.162598, F_score: 0.793298, Accuracy: 0.794235\n",
      "Epoch 117/240, Loss: 317.774719, F_score: 0.761599, Accuracy: 0.771410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/240, Loss: 324.592957, F_score: 0.736524, Accuracy: 0.739531\n",
      "Epoch 119/240, Loss: 324.877686, F_score: 0.717771, Accuracy: 0.727313\n",
      "Epoch 120/240, Loss: 320.424835, F_score: 0.736340, Accuracy: 0.745141\n",
      "Epoch 121/240, Loss: 319.543182, F_score: 0.765727, Accuracy: 0.768022\n",
      "Epoch 122/240, Loss: 318.115936, F_score: 0.741214, Accuracy: 0.753804\n",
      "Epoch 123/240, Loss: 318.743225, F_score: 0.761917, Accuracy: 0.765911\n",
      "Epoch 124/240, Loss: 316.681244, F_score: 0.785881, Accuracy: 0.785405\n",
      "Epoch 125/240, Loss: 317.767670, F_score: 0.752005, Accuracy: 0.760524\n",
      "Epoch 126/240, Loss: 320.794678, F_score: 0.745362, Accuracy: 0.750472\n",
      "Epoch 127/240, Loss: 318.779541, F_score: 0.751839, Accuracy: 0.755304\n",
      "Epoch 128/240, Loss: 317.216705, F_score: 0.782993, Accuracy: 0.786849\n",
      "Epoch 129/240, Loss: 315.610840, F_score: 0.763252, Accuracy: 0.773909\n",
      "Epoch 130/240, Loss: 319.654022, F_score: 0.776336, Accuracy: 0.777130\n",
      "Epoch 131/240, Loss: 315.273224, F_score: 0.771727, Accuracy: 0.779518\n",
      "Epoch 132/240, Loss: 324.026611, F_score: 0.768369, Accuracy: 0.768077\n",
      "Epoch 133/240, Loss: 336.980103, F_score: 0.629732, Accuracy: 0.646562\n",
      "Epoch 134/240, Loss: 343.942719, F_score: 0.639275, Accuracy: 0.650117\n",
      "Epoch 135/240, Loss: 334.613953, F_score: 0.673304, Accuracy: 0.682439\n",
      "Epoch 136/240, Loss: 339.500366, F_score: 0.687205, Accuracy: 0.704543\n",
      "Epoch 137/240, Loss: 329.634674, F_score: 0.639900, Accuracy: 0.671443\n",
      "Epoch 138/240, Loss: 341.735992, F_score: 0.701149, Accuracy: 0.700877\n",
      "Epoch 139/240, Loss: 331.717133, F_score: 0.684547, Accuracy: 0.693769\n",
      "Epoch 140/240, Loss: 332.203430, F_score: 0.698227, Accuracy: 0.722426\n",
      "Epoch 141/240, Loss: 321.926849, F_score: 0.737610, Accuracy: 0.747862\n",
      "Epoch 142/240, Loss: 319.639404, F_score: 0.761986, Accuracy: 0.764245\n",
      "Epoch 143/240, Loss: 321.311371, F_score: 0.740132, Accuracy: 0.748750\n",
      "Epoch 144/240, Loss: 318.848419, F_score: 0.771830, Accuracy: 0.773742\n",
      "Epoch 145/240, Loss: 314.766449, F_score: 0.776225, Accuracy: 0.782906\n",
      "Epoch 146/240, Loss: 313.730682, F_score: 0.796626, Accuracy: 0.798456\n",
      "Epoch 147/240, Loss: 312.821350, F_score: 0.746284, Accuracy: 0.763079\n",
      "Epoch 148/240, Loss: 310.474213, F_score: 0.798521, Accuracy: 0.804232\n",
      "Epoch 149/240, Loss: 312.379974, F_score: 0.708679, Accuracy: 0.746751\n",
      "Epoch 150/240, Loss: 308.832886, F_score: 0.815078, Accuracy: 0.818560\n",
      "Epoch 151/240, Loss: 307.344391, F_score: 0.765743, Accuracy: 0.787848\n",
      "Epoch 152/240, Loss: 307.971710, F_score: 0.824395, Accuracy: 0.826114\n",
      "Epoch 153/240, Loss: 309.385040, F_score: 0.742563, Accuracy: 0.771632\n",
      "Epoch 154/240, Loss: 308.207428, F_score: 0.826754, Accuracy: 0.826891\n",
      "Epoch 155/240, Loss: 308.000885, F_score: 0.785945, Accuracy: 0.797123\n",
      "Epoch 156/240, Loss: 312.411438, F_score: 0.763810, Accuracy: 0.775519\n",
      "Epoch 157/240, Loss: 320.930969, F_score: 0.783709, Accuracy: 0.780573\n",
      "Epoch 158/240, Loss: 314.107788, F_score: 0.728450, Accuracy: 0.753638\n",
      "Epoch 159/240, Loss: 311.829681, F_score: 0.793803, Accuracy: 0.796568\n",
      "Epoch 160/240, Loss: 310.090973, F_score: 0.745271, Accuracy: 0.768355\n",
      "Epoch 161/240, Loss: 310.397491, F_score: 0.788776, Accuracy: 0.797068\n",
      "Epoch 162/240, Loss: 308.889435, F_score: 0.797929, Accuracy: 0.803899\n",
      "Epoch 163/240, Loss: 309.327576, F_score: 0.784256, Accuracy: 0.795402\n",
      "Epoch 164/240, Loss: 317.679535, F_score: 0.788637, Accuracy: 0.788959\n",
      "Epoch 165/240, Loss: 313.304596, F_score: 0.751263, Accuracy: 0.768188\n",
      "Epoch 166/240, Loss: 318.667297, F_score: 0.779571, Accuracy: 0.782128\n",
      "Epoch 167/240, Loss: 316.778320, F_score: 0.749529, Accuracy: 0.759691\n",
      "Epoch 168/240, Loss: 312.043243, F_score: 0.788630, Accuracy: 0.794902\n",
      "Epoch 169/240, Loss: 311.547668, F_score: 0.764578, Accuracy: 0.779962\n",
      "Epoch 170/240, Loss: 309.910217, F_score: 0.824899, Accuracy: 0.824114\n",
      "Epoch 171/240, Loss: 309.210388, F_score: 0.766101, Accuracy: 0.783961\n",
      "Epoch 172/240, Loss: 311.230621, F_score: 0.812809, Accuracy: 0.813007\n",
      "Epoch 173/240, Loss: 306.860748, F_score: 0.778217, Accuracy: 0.793236\n",
      "Epoch 174/240, Loss: 307.100830, F_score: 0.830937, Accuracy: 0.831445\n",
      "Epoch 175/240, Loss: 309.920929, F_score: 0.703116, Accuracy: 0.750417\n",
      "Epoch 176/240, Loss: 312.424042, F_score: 0.798179, Accuracy: 0.800233\n",
      "Epoch 177/240, Loss: 310.374573, F_score: 0.766596, Accuracy: 0.779185\n",
      "Epoch 178/240, Loss: 308.370422, F_score: 0.801560, Accuracy: 0.807953\n",
      "Epoch 179/240, Loss: 310.440186, F_score: 0.800629, Accuracy: 0.804343\n",
      "Epoch 180/240, Loss: 307.344452, F_score: 0.811497, Accuracy: 0.815339\n",
      "Epoch 181/240, Loss: 309.395844, F_score: 0.743628, Accuracy: 0.770521\n",
      "Epoch 182/240, Loss: 308.171570, F_score: 0.812291, Accuracy: 0.813673\n",
      "Epoch 183/240, Loss: 309.628357, F_score: 0.765032, Accuracy: 0.781850\n",
      "Epoch 184/240, Loss: 308.509308, F_score: 0.827319, Accuracy: 0.826558\n",
      "Epoch 185/240, Loss: 311.825684, F_score: 0.762151, Accuracy: 0.778407\n",
      "Epoch 186/240, Loss: 313.365967, F_score: 0.780114, Accuracy: 0.784905\n",
      "Epoch 187/240, Loss: 327.307220, F_score: 0.676655, Accuracy: 0.698545\n",
      "Epoch 188/240, Loss: 337.943573, F_score: 0.686683, Accuracy: 0.698712\n",
      "Epoch 189/240, Loss: 355.432953, F_score: 0.545249, Accuracy: 0.565200\n",
      "Epoch 190/240, Loss: 351.420776, F_score: 0.557563, Accuracy: 0.596746\n",
      "Epoch 191/240, Loss: 341.007019, F_score: 0.654346, Accuracy: 0.655670\n",
      "Epoch 192/240, Loss: 330.217468, F_score: 0.668574, Accuracy: 0.689992\n",
      "Epoch 193/240, Loss: 318.424042, F_score: 0.769532, Accuracy: 0.772798\n",
      "Epoch 194/240, Loss: 309.460846, F_score: 0.783210, Accuracy: 0.796179\n",
      "Epoch 195/240, Loss: 311.150360, F_score: 0.822139, Accuracy: 0.823392\n",
      "Epoch 196/240, Loss: 307.850708, F_score: 0.775774, Accuracy: 0.795346\n",
      "Epoch 197/240, Loss: 310.267975, F_score: 0.823567, Accuracy: 0.823448\n",
      "Epoch 198/240, Loss: 305.952148, F_score: 0.784151, Accuracy: 0.801177\n",
      "Epoch 199/240, Loss: 306.463959, F_score: 0.819314, Accuracy: 0.823559\n",
      "Epoch 200/240, Loss: 307.728943, F_score: 0.769604, Accuracy: 0.787238\n",
      "Epoch 201/240, Loss: 304.122894, F_score: 0.812600, Accuracy: 0.822226\n",
      "Epoch 202/240, Loss: 305.031830, F_score: 0.804064, Accuracy: 0.814284\n",
      "Epoch 203/240, Loss: 303.914124, F_score: 0.816253, Accuracy: 0.823281\n",
      "Epoch 204/240, Loss: 303.675476, F_score: 0.803046, Accuracy: 0.816450\n",
      "Epoch 205/240, Loss: 307.736542, F_score: 0.828005, Accuracy: 0.826447\n",
      "Epoch 206/240, Loss: 308.880035, F_score: 0.710851, Accuracy: 0.757914\n",
      "Epoch 207/240, Loss: 309.469666, F_score: 0.803774, Accuracy: 0.807897\n",
      "Epoch 208/240, Loss: 304.911102, F_score: 0.796814, Accuracy: 0.810785\n",
      "Epoch 209/240, Loss: 304.247589, F_score: 0.823078, Accuracy: 0.828279\n",
      "Epoch 210/240, Loss: 303.956421, F_score: 0.830625, Accuracy: 0.835888\n",
      "Epoch 211/240, Loss: 307.551117, F_score: 0.791076, Accuracy: 0.800400\n",
      "Epoch 212/240, Loss: 314.565247, F_score: 0.787446, Accuracy: 0.789959\n",
      "Epoch 213/240, Loss: 316.371429, F_score: 0.728963, Accuracy: 0.748028\n",
      "Epoch 214/240, Loss: 318.626404, F_score: 0.785874, Accuracy: 0.785016\n",
      "Epoch 215/240, Loss: 309.759399, F_score: 0.776138, Accuracy: 0.789792\n",
      "Epoch 216/240, Loss: 308.362000, F_score: 0.834090, Accuracy: 0.832389\n",
      "Epoch 217/240, Loss: 306.763367, F_score: 0.765707, Accuracy: 0.788015\n",
      "Epoch 218/240, Loss: 306.277527, F_score: 0.824505, Accuracy: 0.825669\n",
      "Epoch 219/240, Loss: 304.466461, F_score: 0.781628, Accuracy: 0.801122\n",
      "Epoch 220/240, Loss: 302.066559, F_score: 0.853588, Accuracy: 0.853660\n",
      "Epoch 221/240, Loss: 301.640320, F_score: 0.795364, Accuracy: 0.814895\n",
      "Epoch 222/240, Loss: 300.524841, F_score: 0.848232, Accuracy: 0.851938\n",
      "Epoch 223/240, Loss: 302.523010, F_score: 0.778778, Accuracy: 0.804065\n",
      "Epoch 224/240, Loss: 309.122437, F_score: 0.806086, Accuracy: 0.812951\n",
      "Epoch 225/240, Loss: 311.481018, F_score: 0.768925, Accuracy: 0.778796\n",
      "Epoch 226/240, Loss: 305.804382, F_score: 0.822950, Accuracy: 0.829001\n",
      "Epoch 227/240, Loss: 304.243439, F_score: 0.811779, Accuracy: 0.821671\n",
      "Epoch 228/240, Loss: 302.581573, F_score: 0.822094, Accuracy: 0.829001\n",
      "Epoch 229/240, Loss: 304.562836, F_score: 0.820959, Accuracy: 0.827335\n",
      "Epoch 230/240, Loss: 302.911194, F_score: 0.806447, Accuracy: 0.817783\n",
      "Epoch 231/240, Loss: 303.589905, F_score: 0.832910, Accuracy: 0.837388\n",
      "Epoch 232/240, Loss: 306.010956, F_score: 0.763609, Accuracy: 0.786349\n",
      "Epoch 233/240, Loss: 305.720398, F_score: 0.816870, Accuracy: 0.822892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/240, Loss: 303.240173, F_score: 0.817734, Accuracy: 0.826280\n",
      "Epoch 235/240, Loss: 300.334747, F_score: 0.826339, Accuracy: 0.836666\n",
      "Epoch 236/240, Loss: 302.431946, F_score: 0.843629, Accuracy: 0.845718\n",
      "Epoch 237/240, Loss: 303.637695, F_score: 0.765161, Accuracy: 0.793624\n",
      "Epoch 238/240, Loss: 308.631775, F_score: 0.817721, Accuracy: 0.820726\n",
      "Epoch 239/240, Loss: 306.293976, F_score: 0.796115, Accuracy: 0.806009\n",
      "Epoch 240/240, Loss: 315.949799, F_score: 0.798208, Accuracy: 0.799511\n"
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "\n",
    "training_status_columns = ['Timestamp', 'F_score', 'Accuracy', 'loss', 'batch_size', 'learning_rate', 'Training_DATASET', 'Continue_with_last_saved_model']\n",
    "df_training_status = pd.DataFrame(columns = training_status_columns)\n",
    "dict_new_epoch_status = {}\n",
    "training_status_file_name = 'model_training_status.csv'\n",
    "training_status_file_path = 'Dashboard/' + training_status_file_name\n",
    "\n",
    "#Continue_training_from_last_saved_model = True\n",
    "Continue_training_from_last_saved_model = False\n",
    "\n",
    "if Training_DATASET == 'SKODA':\n",
    "    no_of_class = 11\n",
    "    no_of_sensor_channel = 30\n",
    "    model_classification_weight = SKODA_Classification_weight\n",
    "    model_training_input = SKODA_X_train_tensor\n",
    "    model_training_target = SKODA_y_train_tensor\n",
    "elif Training_DATASET[0: 11] == 'OPPORTUNITY':\n",
    "    no_of_class = int(Training_DATASET.split(' ')[2])\n",
    "    no_of_sensor_channel = 113\n",
    "    model_classification_weight = OPPORTUNITY_class_weight\n",
    "    model_training_input = OPPORTUNITY_X_train\n",
    "    model_training_target = OPPORTUNITY_y_train\n",
    "    model_testing_input = OPPORTUNITY_X_test\n",
    "    model_testing_target = OPPORTUNITY_y_test\n",
    "else:\n",
    "    print('Please select a Dataset to train the model.')\n",
    "\n",
    "Trained_Model_saving_path = 'Trained_model_pt/' + Training_DATASET + '_Class_' + str(no_of_class) + '.pt'\n",
    "\n",
    "\n",
    "\n",
    "model_training_input = torch.reshape(model_training_input, (model_training_input.size()[0], 1, model_training_input.size()[1], model_training_input.size()[2])).float()\n",
    "\n",
    "\n",
    "epoch_size = 240\n",
    "steps_for_printing_out_loss = 1\n",
    "#BATCH_SIZE = 1200\n",
    "BATCH_SIZE = 100\n",
    "learning_rate = 0.001\n",
    "#learning_rate = 0.02\n",
    "\n",
    "CNN_LSTM_HAR_MODEL_WIP = CNN_LSTM_HAR_MODEL(SILDE_WINDOW, no_of_class, no_of_sensor_channel).to(device)\n",
    "\n",
    "#loss_functioin = nn.CrossEntropyLoss(weight = (torch.tensor([0.2/0.8/17, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])/ (0.2/0.8/17 + 17)).cuda())\n",
    "#loss_functioin = nn.CrossEntropyLoss(weight = torch.tensor(class_count).float().cuda())\n",
    "#loss_functioin = nn.CrossEntropyLoss()\n",
    "loss_functioin = nn.CrossEntropyLoss(weight = torch.tensor(model_classification_weight).float().to(device))\n",
    "\n",
    "#optimizer = optim.SGD(CNN_LSTM_HAR_MODEL_WIP.parameters(), lr = learning_rate)\n",
    "#https://pytorch.org/docs/stable/optim.html\n",
    "optimizer = torch.optim.RMSprop(CNN_LSTM_HAR_MODEL_WIP.parameters(), lr = learning_rate, weight_decay = 0.9)\n",
    "\n",
    "\n",
    "if Continue_training_from_last_saved_model == True:\n",
    "    CNN_LSTM_HAR_MODEL_WIP.load_state_dict(torch.load(Trained_Model_saving_path)['state_dict'])\n",
    "    optimizer.load_state_dict(torch.load(Trained_Model_saving_path)['optimizer'])\n",
    "    CNN_LSTM_HAR_MODEL_WIP.train()\n",
    "\n",
    "\n",
    "\n",
    "training_data_size = list(model_training_input.size())[0]\n",
    "torch.cuda.empty_cache()\n",
    "Training_status_tracker = []\n",
    "for i in range(1, epoch_size + 1):\n",
    "    optimizer.zero_grad()\n",
    "    torch.cuda.empty_cache()\n",
    "    training_no_of_right = 0\n",
    "    training_epoch_loss = 0\n",
    "    for Batch_no in range(int(training_data_size / BATCH_SIZE) + 1):\n",
    "        \"\"\"\n",
    "        if Batch_no % 80 == 1:\n",
    "            print(\"Batch {}/{}\".format(str(Batch_no), int(data_size / BATCH_SIZE)))\n",
    "        \"\"\"\n",
    "        batch_start = Batch_no * BATCH_SIZE\n",
    "        batch_end = min(training_data_size, (Batch_no + 1) * BATCH_SIZE)\n",
    "        \n",
    "        training_input = model_training_input[batch_start: batch_end].to(device)\n",
    "        training_target = model_training_target[batch_start: batch_end].to(device)\n",
    "\n",
    "        training_output = CNN_LSTM_HAR_MODEL_WIP(training_input).to(device)\n",
    "        training_loss = loss_functioin(training_output[:, -1, :], training_target.long()).to(device)\n",
    "        training_epoch_loss += training_loss\n",
    "        training_loss.backward()\n",
    "        if i == 1 or i % (steps_for_printing_out_loss) == 0:\n",
    "            #print('Loss (epoch: ' + str(i) + '): ' + str(loss.cpu().detach().numpy()))\n",
    "            \n",
    "            if Batch_no == 0:\n",
    "                training_All_output = training_output[:, -1, :].argmax(1)\n",
    "            else:\n",
    "                training_All_output = torch.cat((training_All_output, training_output[:, -1, :].argmax(1)), 0)\n",
    "            \n",
    "            for k in range(len(training_target)):\n",
    "                if training_output[:, -1, :].argmax(1)[k] == training_target[k]:\n",
    "                    #print('--------')\n",
    "                    #print(output[k])\n",
    "                    #print(target[k])\n",
    "                    training_no_of_right += 1\n",
    "    if i == 1 or i % (steps_for_printing_out_loss) == 0:\n",
    "        training_F_score = f1_score(model_training_target.numpy(), training_All_output.cpu().detach().numpy(), average='weighted')\n",
    "        \n",
    "        pd.DataFrame(model_training_target.numpy()).to_csv('export/' + 'y_target' + '.csv')\n",
    "        pd.DataFrame(training_All_output.cpu().detach().numpy()).to_csv('export/' + 'y_predict' + '.csv')\n",
    "        #print(CNN_LSTM_HAR_MODEL_WIP.cnn2d_3.weight.grad)\n",
    "        print(\"Epoch {}/{}, Loss: {:.6f}, F_score: {:.6f}, Accuracy: {:.6f}\".format(i, epoch_size, training_epoch_loss.cpu().detach().numpy(), training_F_score, training_no_of_right / training_data_size))\n",
    "        dict_new_epoch_status[training_status_columns[0]] = datetime.datetime.now()\n",
    "        dict_new_epoch_status[training_status_columns[1]] = training_F_score\n",
    "        dict_new_epoch_status[training_status_columns[2]] = training_no_of_right / training_data_size\n",
    "        dict_new_epoch_status[training_status_columns[3]] = training_epoch_loss.cpu().detach().numpy()\n",
    "        dict_new_epoch_status[training_status_columns[4]] = BATCH_SIZE\n",
    "        dict_new_epoch_status[training_status_columns[5]] = learning_rate\n",
    "        dict_new_epoch_status[training_status_columns[6]] = Training_DATASET\n",
    "        dict_new_epoch_status[training_status_columns[7]] = Continue_training_from_last_saved_model\n",
    "        df_training_status = df_training_status.append(dict_new_epoch_status, ignore_index = True)\n",
    "    optimizer.step()\n",
    "torch.save({'state_dict': CNN_LSTM_HAR_MODEL_WIP.state_dict(),'optimizer': optimizer.state_dict()}, Trained_Model_saving_path)\n",
    "\n",
    "if os.path.isfile(training_status_file_path):\n",
    "    df_training_status.to_csv(training_status_file_path, mode='a', header=False)\n",
    "else:\n",
    "    df_training_status.to_csv(training_status_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a Chart to visualize the training process \n",
    "x = df_training_status[training_status_columns[0]].tolist()\n",
    "\n",
    "y1 = df_training_status[training_status_columns[1]].tolist()\n",
    "plt.plot(x, y1, label = \"F_Score\")\n",
    "y2 = df_training_status[training_status_columns[2]].tolist()\n",
    "plt.plot(x, y2, label = \"Accuracy\")\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Training Status')\n",
    "\n",
    "plt.title('Model Training Status')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-a96ba3aab008>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-a96ba3aab008>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    stop here\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Script pending to be cleaned###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_OPPORTUNITY_DATASET_All_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPPORTUNITY_DATASET_FILE_LIST_Training\n",
    "OPPORTUNITY_DATASET_FILE_LIST_Validation\n",
    "OPPORTUNITY_DATASET_FILE_LIST_Testing\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = df_OPPORTUNITY_DATASET_Testing['33 Accelerometer LWR accY'].unique()\n",
    "for m in rr:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPPORTUNITY_DATASET_Training.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPPORTUNITY_DATASET_Testing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPPORTUNITY_DATASET_Validation.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPPORTUNITY_DATASET_Training['file_name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPPORTUNITY_DATASET_All_describe['2 Accelerometer RKN^ accX']['count']\n",
    "df_OPPORTUNITY_DATASET_All_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPPORTUNITY_DATASET_Training['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#len(OPPORTUNITY_column_name_selected)\n",
    "#df_OPPORTUNITY_DATASET_WIP = df_OPPORTUNITY_DATASET[OPPORTUNITY_column_name_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPPORTUNITY_column_name_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_OPPORTUNITY_DATASET_Validation_WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Training_x, Training_y_1, Training_y_2 = data_generator(df_OPPORTUNITY_DATASET_Training_WIP, SILDE_WINDOW, SILDE_WINDOW_STEP, OPPORTUNITY_column_name_selected)\n",
    "Training_x = torch.reshape(Training_x, (Training_x.size()[0], 1, Training_x.size()[1], Training_x.size()[2])).float()\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Testing_x, Testing_y_1, Testing_y_2 = data_generator(df_OPPORTUNITY_DATASET_Testing_WIP, SILDE_WINDOW, SILDE_WINDOW_STEP, OPPORTUNITY_column_name_selected)\n",
    "Testing_x = torch.reshape(Testing_x, (Testing_x.size()[0], 1, Testing_x.size()[1], Testing_x.size()[2])).float()\n",
    "\n",
    "Validation_x, Validation_y_1, Validation_y_2 = data_generator(df_OPPORTUNITY_DATASET_Validation_WIP, SILDE_WINDOW, SILDE_WINDOW_STEP, OPPORTUNITY_column_name_selected)\n",
    "Validation_x = torch.reshape(Validation_x, (Validation_x.size()[0], 1, Validation_x.size()[1], Validation_x.size()[2])).float()\n",
    "\"\"\"\n",
    "#def batch_generator():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_OPPORTUNITY_DATASET_Validation_WIP[OPPORTUNITY_column_name_selected[1: -3]][1: 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_OPPORTUNITY_DATASET_WIP['22 Accelerometer RKN_ accZ'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train[0:5000]).to_csv('sdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SILDE_WINDOW = 24\n",
    "SILDE_WINDOW_STEP = 12\n",
    "\n",
    "\n",
    "def data_generator(ARRAY_OPPORTUNITY_DATASET_x, ARRAY_OPPORTUNITY_DATASET_y, SILDE_WINDOW, SILDE_WINDOW_STEP):\n",
    "    row_no_start = 0\n",
    "    count_index = 0\n",
    "    while (row_no_start + SILDE_WINDOW - 1) <= len(ARRAY_OPPORTUNITY_DATASET_x):\n",
    "        count_index += 1\n",
    "        if count_index % 500 == 0:\n",
    "            print(count_index)\n",
    "        row_no_end = row_no_start + SILDE_WINDOW\n",
    "        df_input = ARRAY_OPPORTUNITY_DATASET_x[row_no_start: row_no_end]\n",
    "        current_input = torch.tensor([df_input])\n",
    "        df_output_Locomotion = ARRAY_OPPORTUNITY_DATASET_y[row_no_end - 1]\n",
    "        df_output_ML_Both_Arms = torch.tensor([df_output_Locomotion])\n",
    "        current_output_ML_Both_Arms = torch.tensor([df_output_ML_Both_Arms])\n",
    "\n",
    "\n",
    "        if row_no_start == 0:\n",
    "            input_tensor = current_input\n",
    "            output_ML_Both_Arms_tensor = current_output_ML_Both_Arms\n",
    "        else:\n",
    "            input_tensor = torch.cat((input_tensor, current_input), 0)\n",
    "            output_ML_Both_Arms_tensor = torch.cat((output_ML_Both_Arms_tensor, current_output_ML_Both_Arms), 0)\n",
    "        row_no_start += SILDE_WINDOW_STEP\n",
    "    return input_tensor, output_ML_Both_Arms_tensor\n",
    "\n",
    "\n",
    "#X_train_tensor_1, y_train_tensor_1 = data_generator(X_train[0: 40000], y_train[0: 40000], SILDE_WINDOW, SILDE_WINDOW_STEP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SILDE_WINDOW = 24\n",
    "SILDE_WINDOW_STEP = 12\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "X_train_tensor, y_train_tensor = data_generator(X_train, y_train, SILDE_WINDOW, SILDE_WINDOW_STEP)\n",
    "\n",
    "pd.DataFrame(y_train_tensor.numpy()).to_csv('export/' + 'y_target' + '.csv')\n",
    "\n",
    "df_target = pd.DataFrame(y_train_tensor.numpy())\n",
    "df_target.columns = ['classification']\n",
    "class_count = df_target['classification'].value_counts()\n",
    "class_count = class_count.sort_index(0)\n",
    "class_count = class_count.tolist()\n",
    "class_count = 1 / (np.array(class_count) / (sum(class_count) / len(class_count)))\n",
    "class_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(class_count)\n",
    "#df_target['abc'].nunique()\n",
    "#df_target\n",
    "#print(X_train_tensor[0])\n",
    "#input_tensor.size()\n",
    "#output_tensor.size()\n",
    "#print(type(class_count))\n",
    "\n",
    "#Class_index = list(class_count.index.values)\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(X_train_tensor[0]).to_csv('0.csv')\n",
    "\n",
    "pd.DataFrame(y_train).to_csv('y.csv')\n",
    "\n",
    "Validation_x = X_train_tensor\n",
    "Validation_x = torch.reshape(Validation_x, (Validation_x.size()[0], 1, Validation_x.size()[1], Validation_x.size()[2])).float()\n",
    "\n",
    "Validation_y_2 = y_train_tensor\n",
    "\n",
    "\n",
    "pd.DataFrame(Validation_x[0, 0, :, :]).to_csv('0v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor.unique()\n",
    "X_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_tensor.unique()\n",
    "#torch.save({'X_train_tensor': X_train_tensor, 'y_train_tensor': y_train_tensor}, 'C:/Users/HX/Magic/training_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.unique(right_classall_clean_array_y)\n",
    "#dict_SKODA_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data_loading = torch.load(\"D:/Installation/yolov4.pt\")\n",
    "X_train_tensor = data_loading['X_train_tensor']\n",
    "y_train_tensor = data_loading['y_train_tensor']\n",
    "data_loading = ''\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pending items:\n",
    "    - batch size = 100\n",
    "    - sensor data were pre-processed to fill in missing values using linear interpolation\n",
    "    - model accuracy & loss function save into array\n",
    "    - Dashboard - to show performance\n",
    "    \n",
    "    - per channel normalization to interval [0,1]\n",
    "    https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input = np.array([random() for i in range(24 * 113 * 1 * 6)]).reshape(6, 1, 24, 113)\n",
    "\n",
    "output = torch.Tensor([[1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                     [0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "                     [0.0, 0.0, 0.0, 1.0, 0.0],\n",
    "                     [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "                     [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "                     [0.0, 0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "\n",
    "output = torch.Tensor([0, 1, 3, 2, 2, 4])\n",
    "\n",
    "final_input = torch.Tensor(input)\n",
    "final_output = torch.Tensor(output)\n",
    "\"\"\"\n",
    "\n",
    "class CNN_LSTM_HAR_MODEL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn2d_1 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = (5, 1))\n",
    "        #self.conv_bn = nn.BatchNorm2d(64)\n",
    "        #self.relu = nn.ReLU()\n",
    "        self.cnn2d_2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (5, 1))\n",
    "        self.cnn2d_3 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (5, 1))\n",
    "        self.cnn2d_4 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (5, 1))\n",
    "        \n",
    "        self.batch_size = 24 - 4 * (5 - 1)\n",
    "        self.hidden_dim = 128\n",
    "        self.input_size = 7232\n",
    "        self.input_size = 1920\n",
    "        self.n_layers = 2\n",
    "        \n",
    "        self.class_no = 11\n",
    "        \n",
    "        #self.lstm1 = nn.LSTM(batch_first = True, input_size  = 7232, hidden_size = self.hidden_dim, num_layers = self.n_layers)\n",
    "        self.lstm1 = nn.LSTM(batch_first = True, input_size  = self.input_size, hidden_size = self.hidden_dim, dropout = 0.5)\n",
    "        self.lstm2 = nn.LSTM(batch_first = True, input_size  = 128, hidden_size = self.hidden_dim, dropout = 0.5)\n",
    "        \n",
    "        #self.lstm1 = nn.LSTM(batch_first = True, input_size  = 7232, hidden_size = self.hidden_dim)\n",
    "        #self.lstm2 = nn.LSTM(batch_first = True, input_size  = 128, hidden_size = self.hidden_dim)\n",
    "        \n",
    "        #self.conv_bn2 = nn.BatchNorm1d(8)\n",
    "        #, dropout = 0.5\n",
    "        #self.input_size = 128\n",
    "        #self.n_layers = 1\n",
    "        #self.lstm2 = nn.LSTM(input_size  = self.input_size, hidden_size = self.hidden_dim, num_layers = self.n_layers, dropout = 0.5)\n",
    "        \n",
    "        #self.fc1 = nn.Linear(128, 18)\n",
    "        self.fc1 = nn.Linear(128, self.class_no)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        x = self.cnn2d_1(x)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.conv_bn(x)\n",
    "        #tensor_to_csv(x[0, -1, :, :], 'layer_1_data_0')\n",
    "        #tensor_to_csv(x[5, -1, :, :], 'layer_1_data_100')\n",
    "        \n",
    "        x = self.cnn2d_2(x)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.conv_bn(x)\n",
    "        #tensor_to_csv(x[0, -1, :, :], 'layer_2_data_0')\n",
    "        #tensor_to_csv(x[5, -1, :, :], 'layer_2_data_100')\n",
    "\n",
    "        x = self.cnn2d_3(x)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.conv_bn(x)\n",
    "        #tensor_to_csv(x[0, -1, :, :], 'layer_3_data_0')\n",
    "        #tensor_to_csv(x[5, -1, :, :], 'layer_3_data_100')\n",
    "\n",
    "        x = self.cnn2d_4(x)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.conv_bn(x)\n",
    "        #tensor_to_csv(x[0, -1, :, :], 'layer_4_data_0')\n",
    "        #tensor_to_csv(x[5, -1, :, :], 'layer_4_data_100')\n",
    "\n",
    "        #print(x.size())\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        #print(x.size())\n",
    "        x = torch.reshape(x, (x.size()[0], x.size()[1], -1))\n",
    "\n",
    "        #hidden = self.init_hidden()\n",
    "        #hidden = (torch.randn(2, x.size()[0], self.hidden_dim).cuda(), torch.randn(2, x.size()[0], self.hidden_dim).cuda())\n",
    "        #x, hidden = self.lstm1(x, hidden)\n",
    "        x, hidden = self.lstm1(x)\n",
    "        x, hidden = self.lstm2(x)\n",
    "        #print(x)\n",
    "        #x = self.conv_bn2(x)\n",
    "        #hidden = self.conv_bn2(hidden)\n",
    "        #tensor_to_csv(x[0, -1, :,], 'layer_lstm1_data_0')\n",
    "        #tensor_to_csv(x[5, -1, :], 'layer_lstm1_data_100')\n",
    "        #print(x)\n",
    "        #hidden2 = (torch.zeros(self.n_layers, 8, self.hidden_dim).requires_grad_(), torch.zeros(self.n_layers, 8, self.hidden_dim).requires_grad_())\n",
    "        ###############################\n",
    "        #x, hidden = self.lstm2(x, hidden)\n",
    "        #print(x)\n",
    "        #x = self.conv_bn2(x)\n",
    "        \n",
    "        #tensor_to_csv(x[0, -1, :,], 'layer_lstm2_data_0')\n",
    "        #tensor_to_csv(x[15, -1, :], 'layer_lstm2_data_100')\n",
    "        #print(x.size())\n",
    "        x = torch.reshape(x, (-1, 128))\n",
    "        #print(x.size())\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        #x = F.softmax(x)\n",
    "        x = torch.reshape(x, (int(x.size()[0] / 8), 8, self.class_no))\n",
    "        x = x[:, -1, :]\n",
    "        #print(x.size())\n",
    "        tensor_to_csv(x, 'layer_fc1_data')\n",
    "        \n",
    "        \n",
    "        tensor_to_csv(x, 'output_data')\n",
    "        \n",
    "        \n",
    "        #print(x)\n",
    "        return x\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        hidden = (weight.new(self.n_layers, self.batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, self.batch_size, self.hidden_dim).zero_())\n",
    "        return hidden\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(Validation_y_2.size())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_csv(tensor_name):\n",
    "    x_np = tensor_name.numpy()\n",
    "    x_df = pd.DataFrame(x_np)\n",
    "    x_df.to_csv('tmp.csv')\n",
    "\n",
    "Validation_x.size()\n",
    "#output\n",
    "\n",
    "tensor_to_csv(output.detach())\n",
    "\n",
    "\n",
    "#Validation_x_to_csv = torch.reshape(Validation_x, (Validation_x.size()[0] * Validation_x.size()[1] * Validation_x.size()[2], Validation_x.size()[3])).float()\n",
    "#tensor_to_csv(Validation_x_to_csv.detach())\n",
    "#tensor_to_csv(Validation_x[1, 0,:, :])\n",
    "\n",
    "#tensor_to_csv(Validation_y_2)\n",
    "\n",
    "for row_no_end in range(0, 155):\n",
    "    print(row_no_end)\n",
    "    print(df_OPPORTUNITY_DATASET_Validation_WIP['250 ML_Both_Arms'][row_no_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.size()\n",
    "target\n",
    "CNN_LSTM_HAR_MODEL_WIP.parameters()\n",
    "target\n",
    "Validation_y_2.sum()\n",
    "print(Validation_y_2)\n",
    "for i in Validation_y_2.long():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in CNN_LSTM_HAR_MODEL_WIP.parameters():\n",
    "    print(i.size())\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.isnan(Validation_x)\n",
    "\n",
    "\n",
    "\n",
    "x_np = Validation_x[0, 0,:, :].numpy()\n",
    "x_df = pd.DataFrame(x_np)\n",
    "x_df.to_csv('tmp.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> rnn = nn.LSTM(10, 20, 2)\n",
    ">>> input = torch.randn(5, 3, 10)\n",
    ">>> h0 = torch.randn(2, 3, 20)\n",
    ">>> c0 = torch.randn(2, 3, 20)\n",
    ">>> output, (hn, cn) = rnn(input, (h0, c0))\n",
    "\n",
    "output.size()\n",
    "#hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = torch.tensor([[[k* 100 + j * 10 + i for i in range (10)] for j in range(10)] for k in range(10)])\n",
    "kk\n",
    "#mm = torch.reshape(kk, (kk.size()[0], 1, kk.size()[1], kk.size()[2])).float()\n",
    "mm = torch.reshape(kk, (kk.size()[0], -1))\n",
    "\n",
    "\n",
    "print(mm.size())\n",
    "\n",
    "print(mm[0])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "mm[:, 0, :, :] == kk\n",
    "mm[5, 0, 4, 3]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in CNN_LSTM_HAR_MODEL_WIP.parameters():\n",
    "    print(para.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPPORTUNITY_DATASET_Training_WIP[OPPORTUNITY_column_name_selected][0:2000].to_csv('def.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2/0.8/17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in CNN_LSTM_HAR_MODEL_WIP.parameters():\n",
    "    print(i.size())\n",
    "    #print(i)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
